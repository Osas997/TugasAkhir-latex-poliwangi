%==================================================================
% Ini adalah bab 3
% Silahkan edit sesuai kebutuhan, baik menambah atau mengurangi \section, \subsection
%==================================================================

\chapter[METODOLOGI PENELITIAN]{\\ METODOLOGI PENELITIAN}

\section{Waktu dan Jadwal Penelitian}

\subsection{Waktu Pelaksanaan Penelitian}
Penelitian ini dilaksanakan dalam rentang waktu 5 bulan dengan pembagian tahapan yang jelas dan terukur. Jadwal penelitian mengikuti prinsip Model Fountain di mana beberapa tahapan dapat berjalan secara paralel dan iteratif.

\subsection{Jadwal Penelitian}

\begin{table}[H]
      \caption{Jadwal Pelaksanaan Penelitian}
      \label{tab:jadwal_pelaksanaan}
      \scriptsize
      \resizebox{\linewidth}{!}{%
            \begin{tabular}{
                  |c
                  |p{0.15\linewidth}
                  |p{0.07\linewidth}|p{0.07\linewidth}|p{0.07\linewidth}
                  |p{0.07\linewidth}|p{0.07\linewidth}|p{0.07\linewidth}|
                  }
                  \hline
                  \multirow{3}{*}{\textbf{No}}            &
                  \multirow{3}{*}{\textbf{Nama Kegiatan}} &
                  \multicolumn{6}{c|}{\textbf{Waktu Pelaksanaan}}                                                                                                                                                                   \\ \cline{3-8}

                                                          &                                      &
                  \multicolumn{5}{c|}{\textbf{2025}}      &
                  \textbf{2026}                                                                                                                                                                                                     \\ \cline{3-8}

                                                          &                                      &
                  \centering\textbf{Agustus}              & \centering\textbf{September}         & \centering\textbf{Oktober} & \centering\textbf{November} & \centering\textbf{Desember} & \textbf{Januari}                        \\
                  \hline

                  1                                       & Analisis Kebutuhan Sistem
                                                          & \cellcolor{yellow}                   &                            &                             &                             &                    &                    \\ \hline

                  2                                       & Pengumpulan Data
                                                          & \cellcolor{yellow}                   &                            &                             &                             &                    &                    \\ \hline

                  3                                       & Cleaning Data
                                                          & \cellcolor{yellow}                   &                            &                             &                             &                    &                    \\ \hline

                  4                                       & Implementasi Data
                                                          & \cellcolor{yellow}                   &                            &                             &                             &                    &                    \\ \hline

                  4                                       & Pengembangan Sistem RAG
                                                          & \cellcolor{yellow}                   &                            &                             &                             &                    &                    \\ \hline

                  5                                       & Pembuatan Proposal
                                                          & \cellcolor{yellow}                   &                            &                             &                             &                    &                    \\ \hline

                  6                                       & Pengumpulan Proposal
                                                          &                                      & \cellcolor{yellow}         &                             &                             &                    &                    \\ \hline

                  7                                       & Pengumuman Finalis (10 Besar)
                                                          &                                      & \cellcolor{yellow}         &                             &                             &                    &                    \\ \hline

                  8                                       & Final \& Presentasi
                                                          &                                      & \cellcolor{yellow}         &                             &                             &                    &                    \\ \hline

                  9                                       & Pengembangan Backend API
                                                          &                                      &                            & \cellcolor{yellow}          & \cellcolor{yellow}          &                    &                    \\ \hline

                  10                                      & Pengujian API
                                                          &                                      &                            &                             &                             & \cellcolor{yellow} &                    \\ \hline

                  11                                      & Analisis Data dan Penyusunan Laporan
                                                          &                                      &                            &                             &                             & \cellcolor{yellow} & \cellcolor{yellow} \\ \hline
            \end{tabular}}
\end{table}


\section{Alur Pelaksanaan Penelitian}

Penelitian ini dilaksanakan secara sistematis dan terstruktur mengikuti tahapan-tahapan yang telah dirancang dalam metodologi Fountain. Setiap tahapan memiliki tujuan dan deliverable yang jelas untuk memastikan pengembangan sistem berjalan sesuai rencana. Berikut adalah rincian alur pelaksanaan penelitian:

\section{Alur Pelaksanaan Penelitian}

Pelaksanaan penelitian ini dilakukan secara sistematis dan terstruktur sesuai dengan jadwal yang ditunjukkan pada Tabel \ref{tab:jadwal_pelaksanaan}. Setiap tahapan dirancang untuk saling berkaitan, dimulai dari tahap perencanaan hingga tahap evaluasi dan penyusunan laporan akhir. Adapun alur pelaksanaan penelitian dijelaskan sebagai berikut.

\begin{longtable}{|c|p{4cm}|p{8.5cm}|}
      \caption{Alur Pelaksanaan Penelitian}
      \label{tab:alur_pelaksanaan}                                                                                                                                                                                                                                                                                    \\
      \hline
      \textbf{No}                          & \textbf{Tahap} & \textbf{Deskripsi}                                                                                                                                                                                                                                      \\
      \hline
      \endfirsthead

      \hline
      \textbf{No}                          & \textbf{Tahap} & \textbf{Deskripsi}                                                                                                                                                                                                                                      \\
      \hline
      \endhead

      \hline
      \endfoot

      \hline
      \endlastfoot

      1                                    &
      Analisis Kebutuhan Sistem            &
      Tahap awal penelitian yang bertujuan untuk mengidentifikasi kebutuhan sistem, baik kebutuhan fungsional seperti fitur chatbot, analisis sentimen, dan RAG, maupun kebutuhan non-fungsional seperti performa, keamanan, dan kemudahan penggunaan. Tahap ini menjadi dasar perancangan sistem secara keseluruhan. \\
      \hline

      2                                    &
      Pengumpulan Data                     &
      Pengumpulan data dilakukan dengan menghimpun dataset yang dibutuhkan untuk analisis sentimen UMKM. Data diperoleh dari hasil scraping atau sumber yang relevan dan disiapkan sebagai bahan utama pengolahan dan analisis pada tahap selanjutnya.                                                                \\
      \hline

      3                                    &
      Cleaning Data                        &
      Data yang telah dikumpulkan kemudian melalui proses pembersihan untuk menghilangkan data duplikat, data tidak valid, serta noise. Tahap ini bertujuan untuk meningkatkan kualitas data agar siap digunakan dalam proses analisis dan pemodelan.                                                                 \\
      \hline

      4                                    &
      Implementasi Data                    &
      Pada tahap ini, data yang telah dibersihkan disusun dan diformat ke dalam struktur yang sesuai untuk kebutuhan sistem, termasuk konversi ke format JSON dan penyesuaian skema agar kompatibel dengan pipeline RAG.                                                                                              \\
      \hline

      5                                    &
      Pengembangan Sistem RAG              &
      Tahap ini mencakup pengembangan sistem Retrieval-Augmented Generation (RAG), meliputi proses ingestion data, pembuatan embedding, penyimpanan vektor, serta perancangan alur query untuk menghasilkan jawaban berbasis konteks data.                                                                            \\
      \hline

      6                                    &
      Pembuatan Proposal                   &
      Penyusunan proposal dilakukan sebagai bagian dari proses akademik dan kompetisi, yang berisi latar belakang, tujuan, metodologi, serta rencana pengembangan sistem yang akan dilakukan.                                                                                                                         \\
      \hline

      7                                    &
      Pengumpulan Proposal                 &
      Proposal yang telah disusun kemudian dikumpulkan sesuai dengan ketentuan yang berlaku, dan menjadi dasar evaluasi untuk tahap seleksi selanjutnya.                                                                                                                                                              \\
      \hline

      8                                    &
      Pengumuman Finalis dan Presentasi    &
      Pada tahap ini dilakukan pengumuman finalis, dilanjutkan dengan tahap final dan presentasi untuk memaparkan sistem yang dikembangkan serta hasil penelitian yang telah dicapai.                                                                                                                                 \\
      \hline

      9                                    &
      Pengembangan Backend API             &
      Tahap ini berfokus pada pengembangan backend API yang mendukung sistem chatbot, termasuk integrasi modul RAG, autentikasi, dan pengelolaan data agar sistem dapat diakses oleh pengguna.                                                                                                                        \\
      \hline

      10                                   &
      Pengujian API                        &
      Pengujian dilakukan menggunakan metode Black Box Testing untuk memastikan seluruh endpoint API berjalan sesuai dengan spesifikasi dan mampu memberikan respons yang benar terhadap berbagai skenario penggunaan.                                                                                                \\
      \hline

      11                                   &
      Analisis Data dan Penyusunan Laporan &
      Tahap akhir penelitian meliputi analisis hasil pengujian sistem serta penyusunan laporan akhir penelitian yang mendokumentasikan seluruh proses, hasil, dan kesimpulan dari penelitian yang dilakukan.                                                                                                          \\
      \hline
\end{longtable}


\section{Metode Pengembangan Sistem}
Penelitian ini menggunakan metode Fountain sebagai pendekatan sistematis dalam pengembangan perangkat lunak. Sebagaimana telah dijelaskan pada Bab 2 bagian Model Fountain, metode ini bersifat iteratif, inkremental, dan memungkinkan tahap-tahapan pengembangan berjalan secara paralel.

Pemilihan metode Fountain didasarkan pada beberapa pertimbangan logis yang sesuai dengan karakteristik penelitian ini:

\begin{enumerate}
      \item \textbf{Pengembangan Paralel antar Komponen}: Sistem yang dikembangkan terdiri dari beberapa komponen utama: backend API (NestJS), frontend (React.js), sistem analisis sentimen (ABSA), sistem rekomendasi konten, dan chatbot RAG. Model Fountain memungkinkan pengembangan komponen-komponen ini dilakukan secara paralel oleh tim, sehingga mempercepat waktu pengerjaan keseluruhan sistem. Misalnya, pengembangan API Gateway dan integrasi LangChain.js dapat dikerjakan bersamaan dengan pengembangan UI chatbot di frontend.

      \item \textbf{Pendekatan Inkremental untuk Fitur Kompleks}: Setiap fitur utama dalam sistem (autentikasi, manajemen data scraping, API Gateway, chatbot RAG) dapat dikembangkan dan ditingkatkan secara bertahap. Pendekatan inkremental ini memungkinkan setiap fitur untuk diuji dan dievaluasi secara independen sebelum diintegrasikan ke dalam sistem keseluruhan, sehingga mengurangi risiko error dan memudahkan debugging.

      \item \textbf{Fleksibilitas dalam Menghadapi Perubahan Requirement}: Pengembangan chatbot RAG dengan knowledge base dinamis (file JSON hasil analisis sentimen) memerlukan fleksibilitas untuk melakukan adjustment terhadap skema data, strategi retrieval, atau prompt template berdasarkan hasil pengujian. Model Fountain memberikan fleksibilitas ini tanpa mengganggu komponen sistem yang sudah berjalan.
\end{enumerate}

Berdasarkan model Fountain, penelitian ini dibagi menjadi beberapa tahapan utama yang dapat berjalan secara paralel dan iteratif:

\subsection{Analisis Kebutuhan Sistem (Analysis)}

Tahap analisis merupakan tahap awal dalam Model Fountain yang bertujuan untuk memahami permasalahan yang akan diselesaikan oleh sistem serta konteks operasionalnya. Pada tahap ini, fokus utama diarahkan pada identifikasi kebutuhan pengguna, alur proses bisnis yang terlibat, serta batasan-batasan sistem yang menjadi ruang lingkup penelitian. Analisis dilakukan untuk memastikan bahwa sistem yang dikembangkan benar-benar relevan dengan permasalahan yang dihadapi oleh pengguna, khususnya pelaku UMKM dalam memahami hasil analisis sentimen media sosial.

Dalam konteks penelitian ini, analisis dilakukan dengan mengkaji bagaimana hasil analisis sentimen Instagram UMKM yang umumnya disajikan dalam bentuk grafik dan data numerik dapat sulit dipahami oleh pengguna non-teknis. Permasalahan tersebut mendorong kebutuhan akan sebuah sistem yang mampu menjembatani data analitik dengan pemahaman pengguna melalui interaksi berbasis bahasa natural. Selain itu, pada tahap ini juga dianalisis batasan sistem, yaitu bahwa penelitian tidak mencakup proses scraping data dan pelatihan model analisis sentimen, melainkan berfokus pada pengembangan backend dan chatbot berbasis Retrieval-Augmented Generation (RAG).

Sesuai dengan karakteristik Model Fountain, hasil analisis pada tahap ini tidak bersifat final dan dapat diperbarui apabila ditemukan kebutuhan baru pada tahap-tahap berikutnya. Dengan demikian, tahap analisis menjadi fondasi awal yang fleksibel dan adaptif bagi keseluruhan proses pengembangan sistem.

\subsection{Spesifikasi Sistem (Requirements Specifications)}

Tahap spesifikasi sistem dalam Model Fountain berfokus pada identifikasi dan pendokumentasian kebutuhan sistem secara lebih terstruktur, baik kebutuhan fungsional maupun non-fungsional. Berbeda dengan model pengembangan yang bersifat linear, pada Model Fountain spesifikasi kebutuhan tidak dianggap sebagai dokumen yang kaku, melainkan dapat direvisi dan disempurnakan seiring dengan berjalannya proses desain, implementasi, dan pengujian sistem.

Pada penelitian ini, spesifikasi sistem disusun berdasarkan hasil analisis kebutuhan pengguna dan tujuan penelitian, serta menjadi acuan utama dalam tahap perancangan dan implementasi. Kebutuhan sistem dikelompokkan menjadi dua kategori utama, yaitu kebutuhan fungsional dan kebutuhan non-fungsional.

\begin{enumerate}
      \item \textbf{Kebutuhan Fungsional}

            Kebutuhan fungsional mendefinisikan fungsi dan layanan utama yang harus disediakan oleh sistem agar dapat memenuhi tujuan penelitian. Kebutuhan ini berkaitan langsung dengan fitur-fitur yang dapat digunakan oleh pengguna dan proses yang dijalankan oleh sistem. Adapun kebutuhan fungsional dalam sistem ini meliputi:
            \begin{itemize}
                  \item Sistem autentikasi dan autorisasi pengguna berbasis JSON Web Token (JWT) untuk memastikan bahwa hanya pengguna terotorisasi yang dapat mengakses layanan sistem.
                  \item Manajemen data hasil scraping Instagram UMKM melalui antarmuka create dan delete guna mengelola data yang digunakan dalam proses analisis dan interpretasi.
                  \item API Gateway untuk layanan Aspect-Based Sentiment Analysis (ABSA) dan sistem rekomendasi konten, yang berfungsi sebagai lapisan orkestrasi antara frontend dan microservices eksternal.
                  \item Chatbot berbasis Retrieval-Augmented Generation (RAG) yang memungkinkan pengguna melakukan interaksi berbasis bahasa natural untuk memperoleh interpretasi kontekstual terhadap hasil analisis sentimen.
            \end{itemize}

      \item \textbf{Kebutuhan Non-Fungsional}

            Kebutuhan non-fungsional mendefinisikan atribut kualitas sistem yang berkaitan dengan performa, keamanan, dan kemudahan pemeliharaan. Kebutuhan ini memastikan bahwa sistem tidak hanya berjalan dengan benar secara fungsional, tetapi juga andal dan nyaman digunakan. Kebutuhan non-fungsional dalam penelitian ini meliputi:
            \begin{itemize}
                  \item Waktu respons chatbot kurang dari 5 detik untuk query standar, mencakup proses embedding query, pencarian similarity, dan pembuatan jawaban oleh model bahasa.
                  \item Keamanan sistem melalui penerapan praktik terbaik, seperti hashing password menggunakan bcrypt, validasi JWT pada endpoint terproteksi, sanitasi input untuk mencegah serangan injeksi, serta penggunaan protokol HTTPS.
                  \item Maintainability sistem melalui penerapan arsitektur modular, prinsip SOLID, penulisan kode yang terdokumentasi dengan baik, serta penggunaan naming convention yang konsisten untuk memudahkan pengembangan dan pemeliharaan lanjutan.
            \end{itemize}
\end{enumerate}

Spesifikasi sistem yang dirumuskan pada tahap ini menjadi dasar bagi tahap desain dan implementasi, serta tetap terbuka untuk penyesuaian apabila diperlukan, sesuai dengan prinsip iteratif dan inkremental yang diusung oleh Model Fountain.


\subsection{Desain Sistem (Design)}
Desain sistem dalam penelitian ini dirancang dengan pendekatan modular dan terstruktur untuk memastikan setiap komponen dapat dikembangkan, diuji, dan dimaintain secara independen namun tetap terintegrasi dengan baik dalam ekosistem keseluruhan. Arsitektur sistem dibangun dengan mempertimbangkan prinsip separation of concerns, scalability, dan maintainability yang menjadi fondasi penting dalam pengembangan perangkat lunak modern berbasis web.


\begin{enumerate}
      \item \textbf{Garis Besar Sistem}

            Sistem chatbot analisis sentimen UMKM dalam penelitian ini dirancang sebagai sebuah ekosistem terintegrasi yang menghubungkan berbagai komponen pemrosesan data secara end-to-end. Secara konseptual, sistem terdiri dari lima komponen utama yang saling berinteraksi dalam alur kerja yang terkoordinasi, mulai dari pengumpulan data hingga penyajian hasil kepada pengguna akhir.

            Alur kerja sistem diawali pada tahap pengumpulan data menggunakan komponen scraping berbasis ekstensi browser, yang bertugas mengekstraksi komentar dari akun Instagram UMKM. Data mentah hasil scraping disimpan dalam format JSON dan dikirimkan ke backend NestJS melalui endpoint REST API yang telah disediakan. Pada tahap ini, backend berperan sebagai pusat koordinasi (\textit{orchestrator}) yang menerima, memvalidasi, dan menyimpan data ke dalam database PostgreSQL, sekaligus menyiapkannya untuk diproses lebih lanjut oleh komponen analitik lainnya.

            Setelah data tersimpan, backend mengonversi dan mengirimkan data dalam format CSV ke sistem Analisis Sentimen berbasis Aspect-Based Sentiment Analysis (ABSA). Sistem ABSA melakukan klasifikasi sentimen terhadap setiap komentar berdasarkan aspek-aspek utama, seperti kualitas produk, harga, dan layanan. Hasil analisis sentimen yang telah diberi label kemudian dikembalikan ke backend untuk disimpan serta dimanfaatkan dalam tahapan berikutnya.

            Data hasil analisis sentimen selanjutnya digunakan secara paralel oleh dua komponen utama. Pertama, data dikirim ke Sistem Rekomendasi Konten yang menganalisis pola sentimen untuk menghasilkan rekomendasi strategi konten, waktu posting optimal, serta saran caption dan hashtag yang relevan. Kedua, data yang sama digunakan sebagai \textit{knowledge base} bagi sistem chatbot berbasis Retrieval-Augmented Generation (RAG), yang memungkinkan pengguna berinteraksi dengan hasil analisis sentimen melalui bahasa natural.

            Seluruh hasil pemrosesan, termasuk ringkasan hasil scraping, distribusi sentimen, serta rekomendasi konten, dikembalikan ke backend dan kemudian diteruskan ke frontend. Frontend yang dibangun menggunakan React.js menyajikan informasi tersebut dalam bentuk dashboard interaktif yang menampilkan visualisasi data sentimen, insight analitik, serta antarmuka chatbot untuk komunikasi dengan pengguna.

            Gambar \ref{fig:garis-besar-sistem} menggambarkan diagram garis besar sistem yang menunjukkan alur data dan interaksi antar komponen, mulai dari tahap scraping hingga penyajian hasil kepada pengguna.

            \begin{figure}[h]
                  \centering
                  \includegraphics[width=0.9\textwidth]{garis-besar-sistem.png}
                  \caption{Diagram Garis Besar Sistem}
                  \label{fig:garis-besar-sistem}
            \end{figure}

            Desain garis besar sistem ini menegaskan prinsip pemisahan tanggung jawab (\textit{separation of concerns}), di mana setiap komponen memiliki peran yang jelas dan dapat dikembangkan secara independen. Backend NestJS berfungsi sebagai orkestrator yang mengelola alur komunikasi dan aliran data antar komponen, sementara setiap layanan pendukung dapat di-\textit{deploy} dan di-\textit{scale} secara terpisah sesuai kebutuhan. Pendekatan ini meningkatkan maintainability, scalability, serta fleksibilitas sistem untuk pengembangan dan optimasi di masa mendatang.


\item \textbf{Use Case Diagram}

Use Case Diagram digunakan untuk menggambarkan interaksi antara pengguna dengan berbagai fungsionalitas yang disediakan oleh sistem, sehingga memberikan gambaran yang jelas dan terstruktur mengenai fitur-fitur utama yang dapat diakses oleh pengguna serta hubungan ketergantungan antar use case dalam sistem chatbot analisis sentimen UMKM. Dalam konteks penelitian ini, pengguna sistem diasumsikan sebagai pelaku UMKM atau pihak yang berkepentingan dengan analisis sentimen media sosial. Berdasarkan Gambar \ref{fig:use-case-diagram}, terdapat beberapa use case utama yang membentuk alur interaksi pengguna dengan sistem, di mana setiap use case dirancang untuk saling terhubung dan membentuk alur yang logis, terstruktur, serta berorientasi pada kebutuhan pengguna dalam memperoleh insight berbasis data sentimen media sosial.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{use case baru.png}
\caption{Use Case Diagram Sistem Analisis Sentimen UMKM}
\label{fig:use-case-diagram}
\end{figure}

Pintu masuk utama bagi pengguna baru dimulai melalui proses registrasi, di mana pengguna dapat membuat akun dengan menyediakan informasi dasar seperti username dan password, lengkap dengan mekanisme validasi input untuk memastikan keamanan, integritas, dan keunikan setiap akun. Setelah registrasi berhasil, sistem dapat secara otomatis mengarahkan pengguna ke halaman utama atau melakukan login otomatis melalui relasi \textit{$\ll$extend$\gg$} menuju use case \textit{Akses Landing Page}, yang bertujuan meningkatkan pengalaman pengguna. Bagi pengguna yang telah memiliki akun, proses autentikasi dilakukan melalui use case \textit{Login}, yang berperan sebagai gerbang akses ke hampir seluruh fitur dalam sistem dan menjadi use case sentral yang menghubungkan berbagai fungsionalitas lainnya.

Setelah terautentikasi, pengguna dapat mengakses dashboard utama, analisis sentimen, chatbot interaktif, serta fitur-fitur pendukung lainnya. Dari sini, akses ke landing page berfungsi sebagai dashboard utama yang menyajikan ringkasan informasi penting, visualisasi data sentimen, dan navigasi ke berbagai fitur analisis, dengan relasi \textit{$\ll$extend$\gg$} yang memungkinkan pengalihan ke proses login bagi pengguna yang belum terautentikasi. Selanjutnya, pengguna dapat meninjau distribusi sentimen secara keseluruhan, ringkasan insight utama, serta analisis berbasis aspek seperti kualitas produk, harga, dan pelayanan melalui use case \textit{Melihat Overall Sentiment, Insight Summary, dan Aspect}, yang hanya dapat diakses setelah login berkat relasi \textit{$\ll$include$\gg$} untuk menjaga keamanan dan privasi data.

Fitur unggulan sistem meliputi interaksi dengan chatbot berbasis Retrieval-Augmented Generation (RAG), di mana pengguna dapat memilih antara interaksi umum melalui \textit{Berinteraksi dengan Chatbot} atau pertanyaan spesifik terkait sentimen melalui \textit{Melihat Sentimen}, keduanya terhubung melalui relasi \textit{$\ll$extend$\gg$} dan memerlukan autentikasi via relasi \textit{$\ll$include$\gg$} dengan \textit{Login}. Melalui chatbot ini, pengguna dapat mengajukan pertanyaan dalam bahasa natural untuk mendapatkan jawaban kontekstual berbasis data aktual, dengan fokus yang lebih tajam pada data sentimen untuk use case khusus.

Selain itu, untuk mendukung transparansi, sistem menyediakan use case \textit{Melihat Data Scrapper} yang memungkinkan pengguna meninjau data hasil scraping Instagram, termasuk konten postingan, komentar, dan metadata, yang juga memerlukan login melalui relasi \textit{$\ll$include$\gg$}. Dari use case ini, pengguna dapat memperluas fungsi melalui relasi \textit{$\ll$extend$\gg$} ke \textit{Menganalisa Data} untuk mengirimkan data ke sistem ABSA guna klasifikasi sentimen berbasis aspek, atau ke \textit{Mengunduh Data} untuk mengekspor data dalam format seperti CSV atau Excel guna analisis lanjutan.

Sistem juga menawarkan use case \textit{Melihat Rekomendasi Konten} yang memberikan saran strategis berdasarkan analisis sentimen, seperti jenis konten optimal, waktu posting, hashtag, dan caption efektif, yang disesuaikan dengan profil bisnis pengguna dan dilindungi oleh relasi \textit{$\ll$include$\gg$} dengan \textit{Login}. Sebagai tambahan, use case \textit{Melihat Research Version} yang terhubung melalui relasi \textit{$\ll$extend$\gg$} dengan \textit{Register} merupakan fitur dashboard analitik sentimen yang menampilkan hasil analisis terhadap berbagai brand UMKM di Jawa Timur, seperti Mie Gacoan, Sambal Bakar, dan UMKM lainnya. Dashboard ini dinamakan \textit{Research Version} karena awalnya dikembangkan dalam rangka mengikuti lomba penelitian atau kompetisi sebelumnya, sehingga lebih bersifat prototipe analitik dan eksploratif dibandingkan fitur utama sistem. Meskipun demikian, fitur ini tetap dapat diakses secara opsional oleh peneliti atau evaluator untuk melihat visualisasi dan perbandingan sentimen lintas brand, namun tidak menjadi fitur wajib bagi pengguna umum.


Secara keseluruhan, Use Case Diagram pada Gambar \ref{fig:use-case-diagram} menyajikan panduan komprehensif mengenai fungsionalitas sistem dari perspektif pengguna, di mana relasi \textit{$\ll$include$\gg$} menunjukkan ketergantungan wajib dan \textit{$\ll$extend$\gg$} menggambarkan hubungan opsional, sehingga memastikan keamanan, privasi, serta modularitas pengembangan untuk maintenance dan penambahan fitur di masa depan.


      \item \textbf{Arsitektur Sistem}

            Arsitektur sistem secara keseluruhan mengadopsi pola API Gateway yang menempatkan backend NestJS sebagai pusat yang menghubungkan berbagai komponen sistem. Arsitektur ini dipilih karena memberikan fleksibilitas tinggi dalam mengelola komunikasi antar services.

            Arsitektur sistem terdiri dari tiga lapisan utama. Lapisan pertama adalah presentation layer yang diimplementasikan menggunakan React.js sebagai frontend framework. Frontend berperan sebagai user interface yang menyediakan antarmuka grafis untuk interaksi pengguna, termasuk visualisasi data sentimen dalam bentuk grafik dan dashboard, serta interface chatbot untuk komunikasi berbasis bahasa natural. Frontend tidak melakukan pemrosesan logika bisnis atau manipulasi data secara langsung, melainkan sepenuhnya bergantung pada API calls ke backend untuk semua operasi data dan komputasi.

            Lapisan kedua adalah application layer yang diimplementasikan menggunakan NestJS sebagai backend framework dan API Gateway. NestJS dipilih karena arsitektur modularnya yang kuat, dukungan penuh terhadap TypeScript yang meningkatkan type safety dan developer experience, serta ekosistem yang matang dengan berbagai built-in features seperti dependency injection, middleware support, dan exception handling. Pada lapisan ini, NestJS berfungsi sebagai request router yang menerima HTTP requests dari frontend, melakukan validasi dan autentikasi menggunakan JWT (JSON Web Token), kemudian meneruskan request ke service yang sesuai, baik internal maupun eksternal.

            Backend NestJS mengelola beberapa modul utama yang masing-masing memiliki tanggung jawab spesifik. Modul autentikasi (Auth Module) menangani proses registrasi, login, dan validasi token JWT untuk memastikan hanya pengguna terotorisasi yang dapat mengakses sistem. Modul manajemen data scraping (Scraping Module) menyediakan endpoint create dan delete untuk mengelola data hasil scraping Instagram yang telah diproses oleh tim kolaborasi. Modul API Gateway (Gateway Module) berperan sebagai proxy yang meneruskan request ke microservices eksternal, yaitu layanan ABSA (Aspect-Based Sentiment Analysis) dan layanan rekomendasi konten, melakukan request transformation, menangani response dari services tersebut, dan menyimpan hasil ke database lokal untuk keperluan caching dan analisis lebih lanjut. Modul chatbot RAG (RAG Module) merupakan komponen inti penelitian ini yang mengimplementasikan pipeline Retrieval-Augmented Generation untuk interpretasi hasil analisis sentimen melalui interaksi bahasa natural.

            Lapisan ketiga adalah data layer yang terdiri dari PostgreSQL sebagai relational database management system dengan ekstensi pgvector yang memungkinkan penyimpanan dan operasi pada vector embeddings. Database ini menyimpan berbagai jenis data, meliputi data pengguna dan kredensial terenkripsi untuk keperluan autentikasi, histori percakapan chatbot yang mencakup pertanyaan pengguna dan jawaban sistem untuk keperluan audit dan improvement, data hasil scraping Instagram beserta metadata-nya yang disimpan dalam format JSON, serta vector embeddings dari dokumen-dokumen yang digunakan sebagai knowledge base untuk sistem RAG.

            \begin{figure}[h]
                  \centering
                  \includegraphics[width=0.8\textwidth]{arsitektur-sistem.png}
                  \caption{High Level Architecture Diagram}
                  \label{fig:high-level-architecture-diagram}
            \end{figure}

            Diagram arsitektur pada gambar \ref{fig:high-level-architecture-diagram} menunjukkan arsitektur sistem yang terdiri dari tiga lapisan utama. Frontend mengirimkan HTTP request ke backend NestJS melalui RESTful API. Backend melakukan autentikasi dan autorisasi menggunakan JWT middleware yang memverifikasi token pada setiap protected endpoint. Setelah validasi berhasil, backend memproses request sesuai dengan business logic yang telah didefinisikan. Untuk operasi yang melibatkan microservices eksternal, backend NestJS bertindak sebagai API Gateway yang meneruskan request ke service ABSA atau rekomendasi, menunggu response, kemudian melakukan data transformation sebelum mengembalikan hasil ke frontend. Untuk operasi chatbot, backend mengakses RAG pipeline yang melakukan embedding query, similarity search pada pgvector, retrieval dokumen relevan, dan generation jawaban menggunakan Large Language Model, kemudian mengembalikan jawaban dalam format JSON ke frontend untuk ditampilkan kepada pengguna.

            Desain arsitektur ini memberikan beberapa keuntungan signifikan. Pertama, separation of concerns memastikan setiap komponen memiliki tanggung jawab yang jelas. Kedua, scalability menjadi lebih mudah karena setiap service dapat di-scale secara independen sesuai kebutuhan traffic dan computational load. Ketiga, maintainability meningkat karena perubahan pada satu komponen tidak mempengaruhi komponen lain selama interface contract tetap dijaga. Keempat, testability menjadi lebih baik karena setiap modul dapat diuji secara unit maupun integration test dengan lebih mudah.
      \item \textbf{Pipeline Retrieval-Augmented Generation (RAG)}

            Pipeline RAG merupakan jantung dari sistem chatbot yang dikembangkan dalam penelitian ini. Pipeline ini dirancang untuk mengatasi keterbatasan Large Language Models konvensional yang rentan menghasilkan hallucination atau informasi yang tidak akurat ketika diminta untuk menjawab pertanyaan tentang domain-specific knowledge yang tidak terdapat dalam training data mereka. Dengan mengintegrasikan mekanisme retrieval, sistem dapat mengakses knowledge base spesifik berisi hasil analisis sentimen UMKM dan menggunakan informasi faktual tersebut sebagai konteks dalam proses generation, sehingga jawaban yang dihasilkan lebih akurat, relevan, dan dapat diverifikasi sumbernya.

            Pipeline RAG dalam penelitian ini terdiri dari dua fase utama yang berjalan secara terpisah namun saling terkait, yaitu RAG Ingestion Pipeline dan RAG Query Pipeline. RAG Ingestion Pipeline merupakan proses offline yang dilakukan ketika ada data baru yang perlu dimasukkan ke dalam knowledge base, sementara RAG Query Pipeline merupakan proses online yang berjalan setiap kali pengguna mengajukan pertanyaan melalui chatbot.

            \begin{enumerate}
                  \item \textbf{RAG Ingestion Pipeline}

                        RAG Ingestion Pipeline merupakan komponen awal dalam sistem Retrieval-Augmented Generation (RAG) yang berfungsi untuk menyiapkan \textit{knowledge base} sebagai sumber informasi utama dalam menjawab pertanyaan pengguna. Pipeline ini dirancang untuk memastikan bahwa data hasil analisis sentimen Instagram UMKM diproses secara sistematis, terstruktur, dan siap digunakan dalam proses pencarian berbasis makna (semantic retrieval). Seluruh tahapan dalam pipeline ini dijalankan secara berurutan agar kualitas data yang disimpan tetap konsisten dan optimal untuk kebutuhan retrieval.

                        \begin{enumerate}
                              \item \textbf{Data Acquisition} Pada tahap ini, sistem menerima file JSON yang berisi hasil analisis sentimen Instagram UMKM. File JSON tersebut memiliki struktur hierarkis yang mencakup berbagai dimensi analisis sentimen. Struktur ini meliputi ringkasan keseluruhan sentimen yang menyajikan jumlah dan persentase sentimen positif, negatif, dan netral, analisis sentimen berdasarkan kategori produk atau layanan, analisis sentimen per brand UMKM, data engagement seperti rata-rata likes dan shares berdasarkan sentimen, serta daftar faktor positif dan negatif yang paling sering muncul dalam komentar pengguna.
                              \item \textbf{Semantic Chunking} Pada tahap ini, dokumen JSON tidak dipecah berdasarkan ukuran karakter atau jumlah token, melainkan berdasarkan struktur dan makna semantik dari data. Pendekatan ini dipilih karena data analisis sentimen secara alami telah terorganisasi dalam unit informasi yang bermakna, seperti sentimen per brand atau per kategori. Sistem melakukan iterasi pada setiap bagian penting dalam JSON, khususnya pada bagian \texttt{sentimen\_per\_brand}, dan membentuk satu dokumen terpisah untuk setiap brand UMKM. Setiap dokumen merepresentasikan satu unit informasi yang utuh, berisi nama brand, distribusi sentimen, rasio sentimen, serta ringkasan insight yang relevan. Dokumen tersebut juga dilengkapi metadata seperti sumber file, jenis analisis, kategori, dan nama brand. Metadata ini berperan penting dalam meningkatkan akurasi pencarian karena memungkinkan sistem melakukan filtering dokumen sesuai konteks pertanyaan pengguna.
                              \item \textbf{Embedding Generation}  Pada tahap ini, setiap dokumen hasil semantic chunking diubah menjadi representasi vektor numerik menggunakan model \textit{Gemini text-embedding-004}. Model embedding ini dipilih karena memiliki kemampuan yang baik dalam memahami teks berbahasa Indonesia, termasuk bahasa informal dan konteks media sosial yang umum ditemukan pada komentar Instagram. Selain itu, model ini menghasilkan vektor dengan dimensi yang efisien namun tetap kaya informasi, sehingga mampu menangkap makna semantik dokumen secara akurat tanpa membebani proses komputasi. Proses embedding dilakukan melalui API embedding yang diintegrasikan menggunakan LangChain, sehingga setiap dokumen teks dikonversi menjadi vektor yang siap digunakan untuk similarity search.
                              \item \textbf{Vector Storage}  Pada tahap ini, vektor embedding beserta metadata dan teks asli dokumen disimpan ke dalam database PostgreSQL yang telah dilengkapi dengan ekstensi \texttt{pgvector}. Penggunaan pgvector memungkinkan database relasional untuk menyimpan dan melakukan pencarian berbasis vektor menggunakan metode similarity seperti cosine similarity. Pendekatan ini dipilih karena memudahkan integrasi dengan sistem backend yang sudah menggunakan PostgreSQL, sekaligus memungkinkan penerapan query hybrid yang menggabungkan pencarian berbasis vektor dan filter berbasis metadata. Sistem ini menerapkan mekanisme penyimpanan bersifat append-only, sehingga data sentimen historis tetap tersimpan dan tidak ditimpa ketika data baru masuk. Pendekatan ini memungkinkan analisis tren sentimen dari waktu ke waktu serta menjaga konsistensi dan integritas data.
                        \end{enumerate}

                        Secara keseluruhan, RAG Ingestion Pipeline memastikan bahwa data sentimen Instagram UMKM diproses secara terstruktur, diubah menjadi representasi semantik yang kaya, dan disimpan dengan mekanisme yang mendukung pencarian kontekstual yang akurat. Alur lengkap dari pipeline ingestion ini ditunjukkan pada Gambar \ref{fig:diagram-ingestion-pipeline}.

                        \begin{figure}[h]
                              \centering
                              \includegraphics[width=0.9\textwidth]{diagram-ingest.png}
                              \caption{Diagram Alur RAG Ingestion Pipeline}
                              \label{fig:diagram-ingestion-pipeline}
                        \end{figure}

                  \item \textbf{RAG Query Pipeline}


                        RAG Query Pipeline merupakan rangkaian proses yang dijalankan ketika pengguna mengajukan pertanyaan melalui antarmuka chatbot. Pipeline ini dirancang untuk menghasilkan jawaban yang cepat, relevan, dan akurat dengan memanfaatkan knowledge base yang telah dipersiapkan sebelumnya melalui RAG Ingestion Pipeline. Seluruh tahapan dalam pipeline ini saling terhubung dan dijalankan secara berurutan untuk memastikan bahwa setiap pertanyaan diproses dengan konteks yang tepat sebelum dikirim ke model bahasa.

                        \begin{enumerate}
                              \item \textbf{Query Reception and Preprocessing}.
                                    Pada tahap ini, sistem menerima pertanyaan pengguna dalam bentuk teks melalui endpoint API chatbot. Teks yang diterima kemudian diproses terlebih dahulu untuk menjaga kualitas dan konsistensi input. Proses preprocessing meliputi penghapusan spasi berlebih di awal dan akhir kalimat (trimming whitespace), normalisasi huruf menjadi huruf kecil (lowercasing), serta sanitasi dasar untuk mencegah potensi serangan seperti injection. Tahapan ini bertujuan memastikan bahwa pertanyaan pengguna berada dalam format yang bersih dan seragam sebelum diproses lebih lanjut.

                              \item \textbf{Query Embedding}.
                                    Setelah preprocessing selesai, pertanyaan pengguna diubah menjadi representasi vektor numerik (embedding) menggunakan model yang sama dengan yang digunakan pada tahap ingestion, yaitu \textit{Gemini text-embedding-004}. Penggunaan model embedding yang konsisten pada kedua pipeline sangat penting untuk menjaga kesesuaian ruang vektor, sehingga perhitungan similarity antara query dan dokumen dapat dilakukan secara akurat. Hasil dari tahap ini adalah sebuah vektor query dengan dimensi yang sama dengan vektor dokumen yang tersimpan dalam knowledge base.

                              \item \textbf{Similarity Search and Retrieval}.
                                    Pada tahap ini, sistem melakukan pencarian dokumen yang paling relevan terhadap query pengguna berdasarkan kesamaan vektor. Metode yang digunakan adalah cosine similarity, yang mengukur kedekatan makna berdasarkan sudut antar vektor, sehingga lebih stabil terhadap perbedaan panjang teks. Proses similarity search dijalankan pada database PostgreSQL dengan ekstensi \texttt{pgvector}, yang telah dioptimalkan menggunakan index untuk meningkatkan performa.

                                    Sistem menerapkan strategi \textit{Top-K retrieval} dengan nilai K = 3, yaitu mengambil tiga dokumen dengan nilai similarity tertinggi. Nilai K yang terlalu kecil berisiko menghilangkan informasi penting, sedangkan nilai K yang terlalu besar dapat memasukkan dokumen yang kurang relevan dan meningkatkan latensi pemrosesan.

                              \item \textbf{Prompt Construction}.
                                    Dokumen-dokumen hasil retrieval kemudian digabungkan dan disusun menjadi sebuah prompt yang akan dikirim ke Large Language Model (LLM). Tahap ini merupakan bagian yang sangat penting karena kualitas prompt berpengaruh langsung terhadap kualitas jawaban yang dihasilkan. Prompt dirancang dengan struktur yang jelas agar LLM dapat memahami konteks dan instruksi secara tepat.

                                    Prompt terdiri dari beberapa komponen utama. Komponen pertama adalah instruksi sistem yang mendefinisikan peran LLM sebagai asisten analisis sentimen UMKM, dengan arahan untuk menjawab pertanyaan secara informatif dan mudah dipahami. Komponen kedua adalah bagian konteks yang berisi dokumen-dokumen hasil retrieval, yang disajikan secara terstruktur agar batas antar dokumen jelas. Komponen ketiga adalah aturan dan batasan yang menginstruksikan LLM untuk hanya menggunakan informasi dari konteks yang diberikan, menggunakan bahasa Indonesia yang formal namun mudah dipahami oleh pelaku UMKM, serta menyampaikan interpretasi praktis dari data numerik. Komponen terakhir adalah pertanyaan asli pengguna, yang diletakkan di bagian akhir prompt untuk menjaga fokus model dalam menghasilkan jawaban yang relevan.

                              \item \textbf{Answer Generation}.
                                    Prompt yang telah dikonstruksi kemudian dikirim ke layanan Groq AI untuk menghasilkan jawaban menggunakan model \textit{openai/gpt-oss-20b}. Pemilihan Groq AI didasarkan pada keunggulannya dalam menyediakan inferensi dengan latensi rendah melalui arsitektur Language Processing Unit (LPU), yang sangat cocok untuk kebutuhan chatbot real-time. Model \textit{openai/gpt-oss-20b} dipilih karena mampu memahami konteks kompleks dan data numerik dengan baik, sekaligus menawarkan keseimbangan antara performa dan efisiensi biaya untuk penggunaan skala produksi.

                              \item \textbf{Rate Limiting}.
                                    Untuk menjaga stabilitas sistem dan mencegah penyalahgunaan, pipeline ini dilengkapi dengan mekanisme rate limiting. Sistem membatasi jumlah permintaan menjadi maksimal 15 request per menit untuk setiap pengguna. Ketika batas ini terlampaui, sistem akan mengembalikan respons HTTP dengan status kode 429 (Too Many Requests), disertai pesan yang menjelaskan bahwa batas penggunaan telah tercapai serta header \textit{Retry-After} yang menunjukkan waktu tunggu sebelum pengguna dapat mengirim permintaan kembali. Mekanisme ini tidak hanya melindungi sistem dari beban berlebih, tetapi juga membantu mengendalikan biaya operasional yang berkaitan dengan pemanggilan API LLM.
                        \end{enumerate}

                        Gambar \ref{fig:diagram-alur-rag-query} menampilkan diagram alur RAG Query Pipeline yang menggambarkan hubungan antar tahapan sejak pertanyaan diterima hingga jawaban akhir dikembalikan kepada pengguna.

                        \begin{figure}[h]
                              \centering
                              \includegraphics[width=0.9\textwidth]{diagram-query-rag.png}
                              \caption{Diagram Alur RAG Query Pipeline}
                              \label{fig:diagram-alur-rag-query}
                        \end{figure}
            \end{enumerate}

      \item \textbf{Desain Database}

            Desain database dalam penelitian ini menggunakan PostgreSQL dengan ekstensi pgvector sebagai backbone untuk menyimpan berbagai jenis data yang diperlukan oleh sistem. Database dirancang dengan pendekatan normalized relational model untuk data struktural dan hybrid approach yang mengkombinasikan relational tables dengan vector storage untuk keperluan RAG.

            \begin{figure}[h]
                  \centering
                  \includegraphics[width=1\textwidth]{ERD.png}
                  \caption{Skema Database dan Relasi Antar Tabel}
                  \label{fig:skema-database}
            \end{figure}

            ERD pada gambar \ref{fig:skema-database} menggambarkan desain database hybrid yang mengombinasikan model relasional ter-normalisasi dengan penyimpanan vektor berbasis pgvector. Struktur dimulai dari tabel inti users, yang menyimpan kredensial sistem seperti username, password, dan refresh\_token. Tabel ini terhubung secara logis ke scrape\_results, yang berfungsi menyimpan hasil scraping atau pengumpulan data eksternal dalam format JSONB melalui kolom data, beserta informasi pengguna terkait (user\_id, username, full\_name, post\_count, dan bio) untuk keperluan pelacakan sumber data.

            Hasil dari scrape\_results kemudian diproses ke tabel sentiment\_result, yang menyimpan keluaran analisis sentimen dan mereferensikan data asalnya melalui foreign key scrape\_result\_id. Setiap hasil sentimen dapat memiliki banyak komentar terklasifikasi yang disimpan di tabel sentiment\_comments, yang mencakup penilaian aspek spesifik seperti food\_quality, price, dan service, dengan nilai berupa enum yang ter-standarisasi, sehingga relasinya bersifat one-to-many dari sentiment\_result ke sentiment\_comments.

            Selain itu, sentiment\_result juga menjadi dasar bagi tabel recommendation\_result, yang menyimpan hasil rekomendasi konten atau posting terbaik berdasarkan data sentimen. Tabel ini terhubung ke dua tabel turunan: recommendation\_best\_posting, yang menyimpan rekomendasi posting optimal beserta skor engagement\_potential, best\_content, alasan rekomendasi (reason), waktu, dan hari serta recommendation\_captions dan recommendation\_hashtags, yang masing-masing menyimpan caption dan hashtag rekomendasi, di mana keduanya memiliki relasi one-to-many terhadap recommendation\_result melalui recommendation\_result\_id.

            Untuk kebutuhan RAG, terdapat tabel langchain\_documents yang berdiri sebagai storage untuk menyimpan dokumen mentah (text) beserta metadata JSONB, dan embedding vektor pada kolom embedding bertipe vector (dari pgvector). Tabel ini tidak selalu memiliki relasi langsung ke pipeline analitik, namun berperan sebagai knowledge backbone, memungkinkan hasil scraping, sentimen, dan rekomendasi untuk diperkaya melalui retrieval berbasis vektor dalam proses RAG.

            Secara keseluruhan, alur relasi database menunjukkan pipeline data berlapis: users $\rightarrow$ scrape\_results $\rightarrow$ sentiment\_result $\rightarrow$ recommendation\_result $\rightarrow$ (best\_posting, captions, hashtags), dengan sentiment\_comments menyimpan detail granular dari analisis sentimen, sementara langchain\_documents mendukung penyimpanan dan pencarian semantik berbasis embedding. Desain ini memastikan konsistensi data struktural melalui normalisasi, sekaligus mendukung query semantik dan similarity search dengan pgvector untuk implementasi RAG.
\end{enumerate}

\subsection{Implementasi Sistem (Coding)}

Tahap implementasi sistem merupakan fase penerjemahan rancangan yang telah dibuat pada tahap desain menjadi sistem yang dapat dijalankan secara nyata. Pada penelitian ini, implementasi dilakukan dengan mengacu pada Model Fountain yang memungkinkan pengembangan dilakukan secara paralel dan iteratif. Dengan pendekatan ini, setiap komponen sistem dapat dikembangkan dan diperbaiki secara bertahap tanpa harus menunggu komponen lain selesai sepenuhnya.

Implementasi sistem mencakup beberapa aspek utama, yaitu penyiapan lingkungan pengembangan, pembangunan basis data, pengembangan arsitektur backend, serta integrasi pipeline Retrieval-Augmented Generation (RAG). Seluruh komponen tersebut dirancang agar dapat saling terhubung dan membentuk sistem chatbot analisis sentimen UMKM yang utuh.

Pendekatan ini memungkinkan sistem untuk dikembangkan secara fleksibel serta mudah disesuaikan jika terjadi perubahan kebutuhan selama proses pengembangan, sehingga selaras dengan karakteristik Model Fountain yang adaptif terhadap perubahan.

\begin{enumerate}
      \item \textbf{Lingkungan Pengembangan dan Konfigurasi}

            Lingkungan pengembangan sistem backend disiapkan menggunakan Node.js sebagai runtime environment untuk memastikan stabilitas dan dukungan jangka panjang. Framework NestJS digunakan untuk membangun aplikasi backend karena menyediakan struktur modular yang rapi dan mendukung pengembangan aplikasi berskala menengah hingga besar. Visual Studio Code dipilih sebagai IDE utama dengan dukungan berbagai ekstensi yang membantu menjaga kualitas dan konsistensi kode.

            Konfigurasi sistem dirancang dengan memisahkan kode aplikasi dan parameter lingkungan. Informasi sensitif seperti kredensial database, API key layanan AI, serta secret token untuk autentikasi disimpan dalam environment variables. Pendekatan ini meningkatkan keamanan sistem sekaligus memudahkan pengelolaan konfigurasi di berbagai lingkungan seperti development dan production.

            Seluruh konfigurasi dimuat ke dalam aplikasi melalui mekanisme dependency injection sehingga setiap modul dapat mengakses parameter yang dibutuhkan secara terstruktur dan aman. Dengan cara ini, perubahan konfigurasi dapat dilakukan tanpa harus memodifikasi kode sumber aplikasi.

      \item \textbf{Implementasi Basis Data}

            Basis data sistem diimplementasikan menggunakan PostgreSQL yang berfungsi sebagai penyimpan utama data aplikasi. PostgreSQL dipilih karena mendukung relasi data yang kompleks serta menyediakan tipe data JSONB yang sesuai untuk menyimpan hasil analisis sentimen dalam format semi-terstruktur. Selain itu, PostgreSQL memiliki performa dan stabilitas yang baik untuk sistem backend.

            Untuk mendukung kebutuhan Retrieval-Augmented Generation, ekstensi pgvector diaktifkan agar database dapat menyimpan embedding teks dalam bentuk vektor numerik. Ekstensi ini memungkinkan sistem melakukan pencarian berbasis kemiripan makna menggunakan metrik seperti cosine similarity, yang menjadi dasar proses retrieval dalam RAG.

            Pengelolaan skema database dilakukan menggunakan ORM sehingga struktur tabel, relasi, dan constraints dapat didefinisikan secara konsisten. Pendekatan ini memudahkan pengembangan, pemeliharaan, serta migrasi skema database di masa mendatang.
      \item \textbf{Implementasi Arsitektur Backend}

            Arsitektur backend diimplementasikan menggunakan pendekatan modular sesuai dengan prinsip yang diterapkan oleh NestJS. Setiap modul dirancang untuk menangani satu domain fungsional tertentu, seperti autentikasi, pengelolaan data scraping, serta pemrosesan RAG. Pembagian ini bertujuan untuk meningkatkan keterbacaan kode dan memudahkan proses pengembangan maupun pengujian.

            Modul autentikasi bertanggung jawab terhadap pengelolaan akses pengguna menggunakan mekanisme JSON Web Token (JWT). Modul ini memastikan bahwa hanya pengguna yang memiliki token valid yang dapat mengakses endpoint tertentu. Sementara itu, modul pengelolaan data scraping menangani penyimpanan dan pengambilan data hasil scraping Instagram yang menjadi sumber utama analisis sentimen.

            Modul RAG merupakan komponen inti yang mengintegrasikan pemuatan dokumen, pembuatan embedding, pencarian dokumen relevan, dan pembuatan jawaban menggunakan model bahasa besar. Seluruh modul saling terhubung melalui service layer sehingga sistem dapat berjalan secara terkoordinasi.

      \item \textbf{Implementasi Pipeline RAG}

            Pipeline Retrieval-Augmented Generation diimplementasikan dalam dua fase utama, yaitu fase ingestion dan fase query. Fase ingestion bertujuan untuk menyiapkan knowledge base dengan memuat data hasil analisis sentimen dari file JSON, kemudian mengubahnya menjadi dokumen teks yang terstruktur berdasarkan kategori informasi seperti ringkasan sentimen dan faktor positif maupun negatif.

            Setiap dokumen pada fase ingestion diubah menjadi embedding menggunakan model embedding yang telah ditentukan, lalu disimpan ke dalam vector store berbasis PostgreSQL dengan ekstensi pgvector. Proses ini dirancang bersifat idempotent agar data tidak disimpan ulang jika sudah tersedia, sehingga meningkatkan efisiensi sistem saat aplikasi dijalankan ulang.

            Fase query berjalan ketika pengguna mengajukan pertanyaan. Pertanyaan diubah menjadi embedding dan dibandingkan dengan embedding dokumen yang tersimpan untuk menemukan konteks yang paling relevan. Konteks tersebut kemudian digunakan oleh model bahasa besar untuk menghasilkan jawaban yang bersifat kontekstual dan berbasis data.

\end{enumerate}

\subsection{Pengujian dan Integrasi (Testing and Integration)}

Tahap pengujian dan integrasi bertujuan untuk memastikan bahwa setiap komponen sistem yang dikembangkan dapat berfungsi sesuai dengan spesifikasi yang telah ditetapkan serta dapat terintegrasi dengan baik sebagai satu kesatuan sistem. Sesuai dengan karakteristik Model Fountain, proses pengujian tidak hanya dilakukan pada tahap akhir pengembangan, melainkan dilaksanakan secara berkelanjutan selama proses implementasi. Pendekatan ini memungkinkan deteksi dan perbaikan kesalahan dilakukan lebih awal, sehingga mengurangi risiko kegagalan sistem pada tahap operasional.

Metode pengujian yang digunakan dalam penelitian ini adalah \textit{Black Box Testing}, yang berfokus pada validasi fungsionalitas sistem tanpa memperhatikan struktur internal atau implementasi kode. Pengujian dilakukan dari perspektif pengguna dengan memverifikasi kesesuaian antara input yang diberikan dan output yang dihasilkan oleh sistem. Untuk mendukung proses ini, Postman digunakan sebagai alat bantu pengujian endpoint REST API yang dikembangkan menggunakan NestJS.

\begin{enumerate}
      \item \textbf{Pengujian Endpoint REST API}
      
      Pengujian dilakukan terhadap seluruh endpoint utama sistem, mencakup modul autentikasi, manajemen pengguna, serta layanan chatbot berbasis Retrieval-Augmented Generation (RAG). Setiap endpoint diverifikasi menggunakan berbagai skenario yang meliputi input valid dan input tidak valid, guna memastikan sistem mampu menangani berbagai kondisi dengan tepat. Hasil pengujian menunjukkan bahwa seluruh endpoint beroperasi sesuai dengan spesifikasi yang ditetapkan, dengan mekanisme validasi input, autentikasi, dan penanganan kesalahan (\textit{error handling}) yang berjalan sebagaimana mestinya.

\renewcommand{\arraystretch}{1.3}
\small
\begin{longtable}{|
      >{\centering\arraybackslash}p{0.8cm} |
      >{\raggedright\arraybackslash}p{3.5cm} |
      >{\centering\arraybackslash}p{1.5cm} |
      >{\raggedright\arraybackslash}p{4.2cm} |
      >{\raggedright\arraybackslash}p{4.2cm} |
      }
      \caption{Skenario dan Rancangan Pengujian Fungsional Endpoint REST API}  \label{tab:test-case} \\
      \hline
      \textbf{No} & \textbf{Endpoint} & \textbf{Method} & \textbf{Test Scenario} & \textbf{Expected Result} \\
      \hline
      \endfirsthead
      \hline
      \textbf{No} & \textbf{Endpoint} & \textbf{Method} & \textbf{Test Scenario} & \textbf{Expected Result} \\
      \hline
      \endhead

1  & /auth/login & POST & Kredensial valid & Access \& refresh token dikembalikan (HTTP 200) \\
\hline
2  & /auth/login & POST & Username tidak terdaftar & Pesan gagal autentikasi (HTTP 400) \\
\hline
3  & /auth/login & POST & Kata sandi salah & Pesan gagal autentikasi (HTTP 400) \\
\hline
4  & /auth/login & POST & Input tidak lengkap/format salah & Pesan validasi (HTTP 400) \\
\hline
5  & /auth/refresh & POST & Refresh token valid & Access token baru terbit (HTTP 200) \\
\hline
6  & /auth/refresh & POST & Refresh token kedaluwarsa/invalid & Pesan gagal autentikasi (HTTP 401) \\
\hline
7  & /auth/me & GET & Permintaan dengan bearer token valid & Data pengguna aktif dikembalikan (HTTP 200) \\
\hline
8  & /auth/me & GET & Permintaan tanpa/ dengan token invalid & Akses ditolak (HTTP 401) \\
\hline
9 & /auth/logout & POST & Logout dengan token valid & Sesi berakhir, HTTP 200 \\
\hline
10 & /auth/logout & POST & Logout tanpa token & Akses ditolak (HTTP 401) \\
\hline
11 & /users/register & POST & Data lengkap dan unik & Akun dibuat (HTTP 201) \\
\hline
12 & /users/register & POST & Username sudah terdaftar & Pesan gagal (HTTP 400) \\
\hline
13 & /users/register & POST & Data kurang lengkap & Pesan validasi (HTTP 400) \\
\hline
14 & /umkm & GET & Permintaan Data Sentimen Umkm & Menampilkan summary data sentimen umkm (HTTP 200) \\
\hline
15 & /rag/query & POST & Pertanyaan valid & Jawaban RAG dikembalikan (HTTP 200) \\
\hline
16 & /rag/query & POST & Payload kosong/invalid & Pesan validasi (HTTP 400) \\
\hline
17 & /rag/query/:scraperId & POST & Pertanyaan valid dengan token sah & Jawaban berbasis data pengguna (HTTP 200) \\
\hline
18 & /rag/query/:scraperId & POST & Permintaan tanpa token & Akses ditolak (HTTP 401) \\
\hline
19 & /rag/query/:scraperId & POST & Payload kosong/invalid & Pesan validasi (HTTP 400) \\
\hline
20 & /rag/insights & GET & Permintaan insight sentimen umkm & Insight sentimen umkm dikembalikan (HTTP 200) \\
\hline
21 & /rag/insights/:scraperId & GET & Token valid, scraper ada & Insight scraper dikembalikan (HTTP 200) \\
\hline
22 & /rag/insights/:scraperId & GET & Token tidak dikirim & Akses ditolak (HTTP 401) \\
\hline
23 & /rag/insights/:scraperId & GET & Scraper tidak ditemukan & Pesan tidak ditemukan (HTTP 404) \\
\hline
24 & /scraping/results & POST & Data valid + file JSON sah + token valid & Data scraping tersimpan (HTTP 201) \\
\hline
25 & /scraping/results & POST & Tidak sertakan token & Akses ditolak (HTTP 401) \\
\hline
26 & /scraping/results & POST & File hilang / format salah / ukuran \> 5MB & Pesan validasi file (HTTP 400) \\
\hline
27 & /scraping/results & GET & Pengguna punya data & Daftar hasil scraping sendiri (HTTP 200) \\
\hline
28 & /scraping/results & GET & Tanpa token & Akses ditolak (HTTP 401) \\
\hline
29 & /scraping/results/:id & DELETE & Hapus data milik sendiri & Data terhapus (HTTP 200) \\
\hline
30 & /scraping/results/:id & DELETE & ID tidak ditemukan & Pesan tidak ditemukan (HTTP 404) \\
\hline
31 & /scraping/results/:id & DELETE & Tanpa token & Akses ditolak (HTTP 401) \\
\hline
32 & /scraping/results/:id/\allowbreak download/csv & GET & Token valid, ID sah & File CSV terunduh (HTTP 200) \\
\hline
33 & /scraping/results/:id/\allowbreak download/csv & GET & Tanpa token & Akses ditolak (HTTP 401) \\
\hline
34 & /scraping/results/:id/\allowbreak download/csv & GET & ID tidak ditemukan & Pesan tidak ditemukan (HTTP 404) \\
\hline
35 & /scraping/results/:id/\allowbreak download/excel & GET & Token valid, ID sah & File XLSX terunduh (HTTP 200) \\
\hline
36 & /scraping/results/:id/\allowbreak download/excel & GET & Tanpa token & Akses ditolak (HTTP 401) \\
\hline
37 & /scraping/results/:id/\allowbreak download/excel & GET & ID tidak ditemukan & Pesan tidak ditemukan (HTTP 404) \\
\hline
38 & /absa/:scraperId & POST & Token valid, scraper ada & Analisis ABSA berhasil dibuat (HTTP 201) \\
\hline
39 & /absa/:scraperId & POST & Tanpa token & Akses ditolak (HTTP 401) \\
\hline
40 & /absa/:scraperId & POST & scraperId bukan UUID valid & Pesan validasi parameter (HTTP 400) \\
\hline
41 & /absa/:scraperId & GET & Token valid, data tersedia & Hasil ABSA dikembalikan (HTTP 200) \\
\hline
42 & /absa/:scraperId & GET & Scraper belum dianalisis & Pesan tidak ditemukan (HTTP 404) \\
\hline
43 & /absa/:scraperId & GET & Tanpa token & Akses ditolak (HTTP 401) \\
\hline
44 & /absa/:scraperId/\allowbreak recommendation & GET & Token valid, rekomendasi tersedia & Rekomendasi berbasis ABSA (HTTP 200) \\
\hline
45 & /absa/:scraperId/\allowbreak recommendation & GET & Scraper tidak ditemukan & Pesan tidak ditemukan (HTTP 404) \\
\hline
46 & /absa/:scraperId/\allowbreak recommendation & GET & Tanpa token & Akses ditolak (HTTP 401) \\
\hline

\end{longtable}


Berdasarkan Tabel \ref{tab:test-case}, pengujian fungsional mencakup 46 skenario yang dirancang secara detail untuk memvalidasi seluruh endpoint sistem. Skenario pengujian dirancang dengan mempertimbangkan kasus positif maupun kasus negatif, yang mencakup aspek-aspek krusial seperti mekanisme autentikasi, validasi input, otorisasi akses, dan penanganan kesalahan. Setiap endpoint diuji dengan metode HTTP yang sesuai, baik GET, POST, maupun DELETE, untuk memastikan respons sistem konsisten dengan spesifikasi. Hasil pengujian menunjukkan bahwa sistem mampu menghasilkan respons yang tepat untuk setiap skenario, termasuk mengembalikan kode status HTTP yang sesuai dan pesan yang informatif. Modul autentikasi berhasil memvalidasi kredensial pengguna dan mengelola token dengan baik, sementara modul manajemen data scraping dapat menangani operasi create dan delete serta ekspor file dalam format CSV dan Excel. Dengan demikian, seluruh endpoint telah memenuhi kriteria keberhasilan yang ditetapkan dan siap untuk diintegrasikan dalam tahap implementasi.

      \item \textbf{Pengujian Relevansi Jawaban Chatbot RAG}

      Selain pengujian fungsional terhadap endpoint REST API, pengujian juga dilakukan terhadap kemampuan chatbot berbasis Retrieval-Augmented Generation (RAG) dalam memberikan jawaban yang relevan dan akurat berdasarkan knowledge base yang tersedia. Pengujian ini bertujuan untuk memvalidasi efektivitas sistem RAG dalam mengekstraksi informasi dari dokumen-dokumen yang telah diindeks dan menghasilkan respons yang sesuai dengan konteks pertanyaan pengguna. Metode pengujian dilakukan dengan merancang serangkaian pertanyaan yang mencerminkan berbagai skenario informasi yang mungkin dicari oleh pengguna, mulai dari pertanyaan deskriptif umum hingga pertanyaan analitis yang memerlukan pemahaman mendalam terhadap data sentimen UMKM. Setiap pertanyaan dirancang untuk menguji aspek berbeda dari kemampuan sistem, termasuk kemampuan retrieval dalam menemukan dokumen yang relevan, kemampuan generation dalam menyusun jawaban yang koheren, serta akurasi dalam menyajikan informasi numerik dan kategorisasi data.


      \begin{longtable}{|c|p{6cm}|p{6cm}|}
\caption{Rancangan Pertanyaan Pengujian Berbasis Knowledge Data}
\label{tab:rancangan-pertanyaan-rag} \\

\hline
\textbf{No} &
\textbf{Questions} &
\textbf{Expected Result} \\
\hline
\endfirsthead

\hline
\textbf{No} &
\textbf{Questions} &
\textbf{Expected Result} \\
\hline
\endhead

\hline
\endfoot

\hline
\endlastfoot

1 &
Apa maksud dari distribusi sentimen keseluruhan? &
Distribusi sentimen menunjukkan bahwa mayoritas komentar bersifat netral, dengan 13.774 komentar (91,9\%), diikuti sentimen positif sebanyak 1.103 komentar (7,4\%), dan sentimen negatif hanya 107 komentar (0,7\%). \\ 
\hline

2 &
Kategori kuliner mana yang memiliki rasio sentimen positif tertinggi? &
Kategori dengan rasio sentimen positif tertinggi adalah Kuliner - Makanan Tradisional dengan rasio positif 15.6\%, diikuti oleh Kuliner - Makanan Asia sebesar 10.8\%. \\
\hline

3 &
Brand mana yang memiliki rasio sentimen positif tertinggi? &
Brand dengan rasio sentimen positif tertinggi adalah Gacoan dengan 15.6\%, diikuti oleh Mieganbatte dengan 12.6\% dan Hisana dengan 10.8\%. \\
\hline

4 &
Bagaimana perbandingan rata-rata likes berdasarkan jenis sentimen? &
Rata-rata likes tertinggi terdapat pada sentimen negatif (251.9), diikuti positif (251.2), dan netral (247.6), menunjukkan bahwa konten negatif cenderung mendapat sedikit lebih banyak likes. \\
\hline

5 &
Apa faktor positif yang paling sering muncul dalam ulasan? &
Kata yang paling sering muncul dalam sentimen positif adalah ``enak'' dengan 277 kemunculan, diikuti ``pas'' (162) dan ``mantap'' (143). \\
\hline
\end{longtable}

Berdasarkan Tabel \ref{tab:rancangan-pertanyaan-rag}, pengujian relevansi jawaban chatbot RAG dilakukan dengan mengajukan lima pertanyaan yang dirancang untuk mengekstraksi informasi spesifik dari knowledge base sistem. Pertanyaan-pertanyaan tersebut mencakup berbagai aspek analisis sentimen, mulai dari distribusi sentimen keseluruhan, perbandingan rasio sentimen berdasarkan kategori dan brand, hingga identifikasi faktor-faktor yang sering muncul dalam ulasan. Setiap pertanyaan memiliki jawaban yang diharapkan berdasarkan data aktual dalam knowledge base, sehingga memungkinkan evaluasi objektif terhadap kemampuan sistem dalam melakukan retrieval dan generation yang akurat. Hasil pengujian menunjukkan bahwa chatbot RAG mampu memberikan jawaban yang relevan dan konsisten dengan data yang tersimpan, dengan tingkat akurasi informasi numerik dan kategorisasi yang tinggi. Sistem berhasil mengekstrak informasi dari dokumen-dokumen terkait dan menyajikannya dalam format yang mudah dipahami oleh pengguna. Temuan ini mengonfirmasi bahwa integrasi antara mekanisme retrieval berbasis vektor dan model generatif berfungsi dengan baik dalam konteks analisis sentimen UMKM.

\end{enumerate}

\subsection{Operasi Sistem (Operation)}
Tahap operasi merupakan fase di mana sistem yang telah melalui proses implementasi dan pengujian mulai dijalankan dalam lingkungan operasional nyata. Pada tahap ini, sistem chatbot analisis sentimen UMKM digunakan untuk menerima permintaan pengguna, memproses data melalui layanan backend, serta menghasilkan respons berbasis analisis sentimen dan Retrieval-Augmented Generation (RAG).

Operasi sistem mencakup penggunaan endpoint REST API oleh frontend untuk autentikasi pengguna, pengambilan data, serta interaksi dengan chatbot. Kinerja sistem pada tahap ini diamati untuk memastikan stabilitas layanan, konsistensi respons, serta kesesuaian antara perilaku sistem dan kebutuhan pengguna. Tahap operasi juga berperan sebagai sumber umpan balik awal yang digunakan untuk mengevaluasi efektivitas sistem sebelum memasuki tahap pemeliharaan.

\subsection{Pemeliharaan Sistem (Maintenance)}

Tahap pemeliharaan dalam Model Fountain berfokus pada upaya menjaga agar sistem tetap berjalan dengan baik setelah digunakan dalam lingkungan operasional. Aktivitas maintenance meliputi perbaikan kesalahan (\textit{bug fixing}), peningkatan performa sistem, serta pemantauan kestabilan layanan melalui mekanisme logging dan monitoring.

Dalam penelitian ini, pemeliharaan sistem dilakukan dengan memanfaatkan arsitektur modular NestJS yang memungkinkan perbaikan pada satu modul tanpa memengaruhi modul lain. Selain itu, feedback dari pengguna dan hasil observasi pada tahap operasi digunakan sebagai dasar dalam menentukan prioritas perbaikan dan penyesuaian sistem.

\subsection{Evolusi Sistem (Evolution)}
Tahap evolusi merupakan kelanjutan dari tahap pemeliharaan, di mana sistem dikembangkan lebih lanjut untuk menyesuaikan dengan kebutuhan jangka panjang dan perubahan lingkungan. Evolusi sistem dalam Model Fountain memungkinkan penambahan fitur baru atau peningkatan kemampuan sistem tanpa harus membangun ulang keseluruhan sistem.

Dalam konteks penelitian ini, evolusi sistem dapat mencakup penambahan sumber data media sosial baru, peningkatan model analisis sentimen dan model bahasa yang digunakan dalam chatbot, serta pengembangan fitur analitik lanjutan. Dengan pendekatan ini, sistem chatbot analisis sentimen UMKM diharapkan dapat berkembang secara berkelanjutan, adaptif terhadap perubahan kebutuhan pengguna, dan tetap relevan dalam jangka panjang.